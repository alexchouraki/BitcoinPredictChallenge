---
title: "Super projet BTC-NLP"
output: html_notebook
---

```{r}
library(lubridate)
library(tidyverse)
```

# Principes généraux

Le but de l'exercice est d'essayer de prédire l'évolution du cours du Bitcoin.

- Ici, on se concentrera uniquement sur la variable binaire "Est-ce que le bitcoin a monté ou a baissé entre deux journées" ?

- On ne se souciera donc pas de *quantifier* la prédiction de hausse ou de baisse du bitcoin.

Pour cela, plusieurs idées possibles :

- Utiliser les données Google Trends pour voir un peu les tendances haussières / baissières

- Faire du NLP sur les forums de Bitcoin (sentiment analysis ?)

- Essayer de faire une analyse technique financière d'après le Bitcoin


# Retrieve the Bitcoin data

For information, the file `bitcoin_price.csv` has been downloaded from Coindesk ([available here](https://www.coindesk.com/price/)).

```{r}
bitcoin.data = read.csv("./data/bitcoin_price.csv")
```

## Cleaning the data a bit

```{r}
bitcoin.data = bitcoin.data %>% filter(!is.na(Close.Price)) # Remove the last two lines
```

```{r}
bitcoin.data$Date = bitcoin.data$Date %>% # Remove the time from the date
  sapply(as.character) %>%
  sapply(substr, 1, 10)

bitcoin.data$Date = ymd(bitcoin.data$Date) # Transform the date from string into a lubridate
```

## Generate the binary variable we need to predict

```{r}
binary.variable = rep(NA, nrow(bitcoin.data) - 1)

for(i in c(1:(nrow(bitcoin.data) - 1))){
  
  if(bitcoin.data$Close.Price[i] > bitcoin.data$Close.Price[i+1]){
    
    binary.variable[i] = "Down"
    
  } else {binary.variable[i] = "Up"}
  
}


bitcoin.data = bitcoin.data %>% filter(Date != ymd("2015-12-31"))
```

```{r}
bitcoin.data$Trend = binary.variable
```


## Result: data that is clean, with the proper variable to predict
```{r}
colnames(bitcoin.data) = c('date', 'close.price', 'trend')
```


# Données regroupées
```{r}
NLP_data = read.csv('./data/NLP_grouped_data.csv')
NLP_data
```

## Reformater la date
```{r}
NLP_data$date = NLP_data$date %>% # Remove the time from the date
  sapply(as.character)

NLP_data$date = ymd(NLP_data$date)
```

## Join
```{r}
full_data = inner_join(NLP_data, bitcoin.data)
full_data$trend = as.factor(full_data$trend)
```

## Adding new features
### Moving average for the number of posts


## Moving average

```{r}
library(pracma)
full_data$time.diff.movavg = full_data$post - movavg(full_data$post, 7)
full_data$close.price.movavg = full_data$close.price - movavg(full_data$close.price, 7)
```

## Adding a lag of one day
```{r}
column_names = colnames(full_data)

for(column in colnames(full_data)){
  
  full_data = data.frame(full_data,
                        c(NA, full_data[[column]][c(1:(nrow(full_data)) - 1)]))
  
}

# Change column names to be a bit cleaner
colnames(full_data) = c(column_names, paste0(column_names, '.D1'))
```


```{r}
full_data = full_data %>% dplyr::select(-date.D1)
full_data$trend.D1 = factor(full_data$trend.D1, levels = c(1, 2), labels = c('Down', 'Up'))
```

```{r}
full_data$trend.D2 = c(NA, full_data$trend.D1[c(1:nrow(full_data) - 1)])
full_data$trend.D2 = factor(full_data$trend.D2, levels = c(1, 2), labels = c('Down', 'Up'))
```

```{r}
full_data = full_data %>% filter(date >= ymd('2017-05-01') & date <= ymd('2018-07-31'))
```

## Split by training and testing data
Train: between May 1st 2017 and April 30th 2018
Test: between May 1st 2018 and July 31st 2018

```{r}
scale_data = full_data
#scale_data[,-c(1,7,15)] = scale(scale_data[,-c(1,7,15)])

train_data = full_data %>% filter(date >= ymd('2017/05/01') & date < ymd('2018/05/01'))
test_data = full_data %>% filter(date >= ymd('2018/05/01') & date <= ymd('2018/07/31'))
```

# Attemps to classify

## Dummy classifier
```{r}
max(sum(test_data$trend == "Up"), sum(test_data$trend == "Down")) / nrow(test_data)
```

```{r}
colnames(full_data)
```


## Logistic regression
```{r}
reg.model = glm(trend ~ polarity + polarity.D1 + close.price.D1 + polarity_and_log_merit + polarity_and_log_merit.D1 + trend.D1,
                family = "binomial",
                data = train_data)

summary(reg.model)
```



```{r}
reg.predict = predict(reg.model, test_data, type = "response")
reg.prediction = prediction(reg.predict, test_data$trend)
reg.perf = performance(reg.prediction, measure = "tpr", x.measure = "fpr")
plot(reg.perf)
```

```{r}
reg.auc = performance(reg.prediction, measure = "auc")
reg.auc = reg.auc@y.values[[1]]
reg.auc
```

```{r}
prediction_vector = rep(NA, nrow(test_data))
prediction_vector[predict(reg.model, test_data, type = "response") > 0.5] = "Up"
prediction_vector[is.na(prediction_vector)] = "Down"

sum(prediction_vector == test_data$trend) / nrow(test_data)
```

```{r}
prediction_vector = rep(NA, nrow(train_data))
prediction_vector[predict(reg.model, train_data, type = "response") > 0.5] = "Up"
prediction_vector[is.na(prediction_vector)] = "Down"

sum(prediction_vector == train_data$trend) / nrow(train_data)
```


## Random Forest

```{r}
set.seed(0)
rf.model = randomForest(trend ~ date + polarity + polarity.D1 + polarity_and_log_merit.D1 + trend.D1 + time.diff.movavg.D1, ntree = 5000, nodesize = 1,
                data = train_data)
```

```{r}
sum(predict(rf.model, test_data, type = "response") == test_data$trend) / nrow(test_data)
```

```{r}
sum(predict(rf.model, train_data, type = "response") == train_data$trend) / nrow(train_data)
```



# Quelques réflexions sur des pistes à suivre

## Analyse technique sur le cours
Pas facile à implémenter, d'autant plus que je pense qu'une des suppositoins, c'est que nos prédictions sont indépendantes (i.e. la prédiction pour le jour j doit être indépendante de celle pour le jour j+1 ou celle pour le jour j-1).

A voir si on a le droit d'utiliser les données "déjà passées" pour faire des prédictions futures (i.e. si on veut faire une prédiction pour le 10 mai, est-ce qu'on a le droit d'utiliser le cours du 1 au 9 mai ?)

## Google Trends
Piste intéressante. Mais problème : à partir d'un certain stade, les données Google Trends s'obtiennent par semaine, et plus par jour, donc on n'a plus grand chose d'exploitable.

```{r}
trends = read.csv('./data/trends.csv')
trends$date = ymd(trends$date)
```

### Graphe correspondant (exemple Bitcoin)

```{r}
ggplot(data = trends,
       aes(x = date, y = cryptocurrency)) +
  geom_line()
```

# Modélisation
```{r}
library(ROCR)
library(randomForest)
```

## On réunit les datasets pour former un truc complet
```{r}
trend.data = data.frame(trends, "bitcoin.value" = bitcoin.data$Close.Price, "bitcoin.trend" = bitcoin.data$Trend)
trend.data
```


### Split entre training et test dataset
```{r}
set.seed(0)
train.sample = c(1:nrow(trend.data)) %in% sample(c(1:nrow(trend.data)), as.integer(nrow(trend.data) * 0.8))
train.trend = trend.data[train.sample,]
test.trend = trend.data[!train.sample,]
```

## Quelle précision de base ?
```{r}
max(sum(test.trend$bitcoin.trend == "Up"), sum(test.trend$bitcoin.trend == "Down")) / nrow(test.trend)
```

La précision du dummy model (qui prédit toujours la même chose) sera donc de $51.3\%$.

## Premier modèle tout con : régression logistique
```{r}
reg.model = glm(bitcoin.trend ~ date + bitcoin + btc + hodl + blockchain, family = binomial, data = train.trend)
```

```{r}
reg.predict = predict(reg.model, test.trend, type = "response")
reg.prediction = prediction(reg.predict, test.trend$bitcoin.trend)
reg.perf = performance(reg.prediction, measure = "tpr", x.measure = "fpr")
plot(reg.perf)
```

```{r}
reg.auc = performance(reg.prediction, measure = "auc")
reg.auc = reg.auc@y.values[[1]]
reg.auc
```

## Autre type de modèle : Random forest
```{r}
set.seed(0)
rf.model = randomForest(bitcoin.trend ~ date + bitcoin + btc + hodl + blockchain, mtry = 3, data = train.trend)
```

```{r}
sum(predict(rf.model, test.trend, type = "response") == test.trend$bitcoin.trend) / nrow(test.trend)
```



# Mélange Google Trends / NLP

```{r}
merged_trends = read.csv('./data/merged_trends.csv')
colnames(merged_trends) = c("date", paste0('gt.', colnames(merged_trends)[2:ncol(merged_trends)]))
merged_trends$date = full_data$date
full_data = inner_join(full_data, merged_trends)
```

## Définition modèle train / modèle test

```{r}
scale_data = full_data
scale_data[,-c(1,7,15,18)] = scale_data %>% select_if(is.numeric) %>% scale()

train_data = scale_data %>% filter(date >= ymd('2017/05/01') & date < ymd('2018/05/01'))
test_data = scale_data %>% filter(date >= ymd('2018/05/01') & date <= ymd('2018/07/31'))
```

## Régression logistique

```{r}
colnames(full_data)
```


```{r}
full.reg.model = glm(as.formula(paste0("trend ~ ", paste0(colnames(full_data)[-c(6,7,9)], collapse = " + "))),
                family = "binomial",
                data = train_data)

summary(full.reg.model)
```

### ROC et AUC
```{r}
full.reg.predict = predict(full.reg.model, test_data, type = "response")
full.reg.prediction = prediction(full.reg.predict, test_data$trend)
full.reg.perf = performance(full.reg.prediction, measure = "tpr", x.measure = "fpr")
plot(full.reg.perf)
```

```{r}
reg.auc = performance(full.reg.prediction, measure = "auc")
reg.auc = reg.auc@y.values[[1]]
reg.auc
```

### Précision
```{r}
prediction_vector = rep(NA, nrow(test_data))
prediction_vector[predict(full.reg.model, test_data, type = "response") > 0.5] = "Up"
prediction_vector[is.na(prediction_vector)] = "Down"

print(paste0('Precision on test data: ', sum(prediction_vector == test_data$trend) / nrow(test_data)))
```

```{r}
prediction_vector = rep(NA, nrow(train_data))
prediction_vector[predict(full.reg.model, train_data, type = "response") > 0.5] = "Up"
prediction_vector[is.na(prediction_vector)] = "Down"

print(paste0('Precision on test data: ', sum(prediction_vector == train_data$trend) / nrow(train_data)))
```

On peut noter qu'il y a très peu de variables pour lesquelles la p-valeur est inférieur à 0.05 (seulement l'indice Google Trends pour le mot-clé "btc" et pour "hodl"). On va donc enlever quelques variables pour voir si cela peut aider à augmenter la précision.

## Régression logistique avec moins de variables
```{r}
few.reg.model = glm(as.formula(paste0("trend ~ ", paste0(colnames(full_data)[-c(1,3,4,5,6,7,9,10,11,16,17,21)], collapse = " + "))),
                family = "binomial",
                data = train_data)

summary(fewer.reg.model)
```

```{r}
fewer.reg.predict = predict(fewer.reg.model, test_data, type = "response")
fewer.reg.prediction = prediction(fewer.reg.predict, test_data$trend)
fewer.reg.perf = performance(fewer.reg.prediction, measure = "tpr", x.measure = "fpr")
plot(fewer.reg.perf)
```

```{r}
reg.auc = performance(fewer.reg.prediction, measure = "auc")
reg.auc = reg.auc@y.values[[1]]
reg.auc
```

```{r}
prediction_vector = rep(NA, nrow(test_data))
prediction_vector[predict(fewer.reg.model, test_data, type = "response") > 0.5] = "Up"
prediction_vector[is.na(prediction_vector)] = "Down"

print(paste0('Precision on test data: ', sum(prediction_vector == test_data$trend) / nrow(test_data)))
```

```{r}
prediction_vector = rep(NA, nrow(train_data))
prediction_vector[predict(fewer.reg.model, train_data, type = "response") > 0.5] = "Up"
prediction_vector[is.na(prediction_vector)] = "Down"

print(paste0('Precision on test data: ', sum(prediction_vector == train_data$trend) / nrow(train_data)))
```

```{r}
colnames(full_data)
```


## Dernière régression logistique avec encore moins de variables
```{r}
few.reg.model = glm(as.formula(paste0("trend ~ ", paste0(colnames(full_data)[-c(1,3,4,5,6,7,8,9,10,11,16,17,21)], collapse = " + "))),
                family = "binomial",
                data = train_data)

summary(few.reg.model)
```

```{r}
few.reg.predict = predict(few.reg.model, test_data, type = "response")
few.reg.prediction = prediction(few.reg.predict, test_data$trend)
few.reg.perf = performance(few.reg.prediction, measure = "tpr", x.measure = "fpr")
plot(few.reg.perf)
```

```{r}
reg.auc = performance(few.reg.prediction, measure = "auc")
reg.auc = reg.auc@y.values[[1]]
reg.auc
```

```{r}
prediction_vector = rep(NA, nrow(test_data))
prediction_vector[predict(few.reg.model, test_data, type = "response") > 0.5] = "Up"
prediction_vector[is.na(prediction_vector)] = "Down"

print(paste0('Precision on test data: ', sum(prediction_vector == test_data$trend) / nrow(test_data)))
```

```{r}
prediction_vector = rep(NA, nrow(train_data))
prediction_vector[predict(few.reg.model, train_data, type = "response") > 0.5] = "Up"
prediction_vector[is.na(prediction_vector)] = "Down"

print(paste0('Precision on test data: ', sum(prediction_vector == train_data$trend) / nrow(train_data)))
```